{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from nltk import clean_html\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SCRAPE VOTERS\n",
    "\n",
    "# set url\n",
    "voterlist_url = 'http://www.bfi.org.uk/films-tv-people/sightandsoundpoll2012/voters'\n",
    "\n",
    "# initialize lists of voters with header labels\n",
    "voters_list = [['voterid', 'name', 'category', 'country', 'gender', 'film1', 'film2', 'film3', 'film4', 'film5', 'film6', 'film7', 'film8', 'film9', 'film10', 'comment']]\n",
    "\n",
    "# deal with manual filmid creation\n",
    "filmid_manual = 1000\n",
    "filmid_manual_dict = {}\n",
    "\n",
    "# open main BFI voters page and extract the tables with lists of voters\n",
    "bfi_soup = BeautifulSoup(requests.get(voterlist_url).content, 'html5lib')\n",
    "tables = bfi_soup.findAll('table', attrs= {'class':'sas-poll'})\n",
    "bfi_soup.decompose()\n",
    "\n",
    "# parse through each voter (under a distinct <tr> tag)\n",
    "for table in tables[24:]:\n",
    "    trs = table.findAll('tr')\n",
    "    for tr in trs:\n",
    "\n",
    "        # extract voterid and save link\n",
    "        voter_url = tr.find('a').get('href')\n",
    "        voter_info = [voter_url.split('/')[-1]]\n",
    "\n",
    "        # extract voter name, type, country, and gender\n",
    "        voter_info.extend([cell.text.encode('UTF-8') for cell in tr.findAll('td')])\n",
    "\n",
    "        # open voter page\n",
    "        voter_soup = BeautifulSoup(requests.get(voter_url).content, 'html5lib')\n",
    "        film_table = voter_soup.find('table', attrs= {'class':'sas-poll'})\n",
    "\n",
    "        # extract ten filmids\n",
    "        for tr in film_table.findAll('tr'):\n",
    "            try:\n",
    "                link = tr.findNext('td').findNext('p').find('a')\n",
    "                voter_info.append(link.get('href').split('/')[-1])\n",
    "            except:\n",
    "                filmid_manual_info = [cell.text for cell in tr.findAll('td')]\n",
    "                if filmid_manual_info[0] in filmid_manual_dict:\n",
    "                    voter_info.append(filmid_manual_dict.get(filmid_manual_info[0])[0])\n",
    "                else:\n",
    "                    filmid_manual_dict[filmid_manual_info[0]] = [filmid_manual, filmid_manual_info[1], filmid_manual_info[2]]\n",
    "                    voter_info.append(filmid_manual)\n",
    "                    filmid_manual += 1\n",
    "\n",
    "        # extract voter comment\n",
    "        try:\n",
    "            voter_info.append(voter_soup.find('div', attrs= {'class':'wysiwyg'}).get_text().strip().encode('UTF-8'))\n",
    "        except:\n",
    "            voter_info.append('')\n",
    "            \n",
    "        # append info on this single voter to the list of all voters\n",
    "        voter_soup.decompose()\n",
    "        voters_list.append(voter_info)\n",
    "        print(voter_info)\n",
    "\n",
    "    df = pd.DataFrame(voters_list)\n",
    "    df.to_csv(csv_dir+'/bfi-voters101.csv', sep=',', encoding='utf-8')\n",
    "    \n",
    "    # write voter info to csv\n",
    "    with open(os.getcwd()+'/bfi-voters100.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(voters_list)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SCRAPE FILMS\n",
    "\n",
    "# set base url\n",
    "film_url = 'http://www.bfi.org.uk/films-tv-people/'\n",
    "\n",
    "# initialize lists of films with header labels\n",
    "film_list = [['filmid', 'title', 'director', 'country', 'year', 'genre', 'type', 'category']]\n",
    "\n",
    "# add manual filmids to list\n",
    "for k,v in filmid_manual_dict.items():\n",
    "    film_list.append([v[0], k.encode('UTF-8'), v[2].encode('UTF-8'), '', v[1].encode('UTF-8'), '', '', ''])\n",
    "\n",
    "# get list of unique filmids from voter_list\n",
    "filmid_list = []\n",
    "for i in voters_list[:3]:\n",
    "    for j in i[5:-1]: filmid_list.append(j)\n",
    "filmid_list = set(filmid_list)\n",
    "\n",
    "# visit each of the film webpages\n",
    "for filmid in filmid_list:\n",
    "    if str(filmid)[0] != '4': continue\n",
    "    film_soup = BeautifulSoup(requests.get(film_url+str(filmid)).content, 'html5lib')\n",
    "\n",
    "    # extract film title and append with film id\n",
    "    film_info = [filmid, film_soup.find('title').contents[0].split('(')[0].strip().encode('UTF-8')]\n",
    "\n",
    "    # extract director(s)\n",
    "    try:\n",
    "        film_info.append(\" & \".join([director.text for director in film_soup.find('p', text=re.compile('Director.*'), attrs={'class':'row-label'}).findNext('p').findAll('a')]).encode('UTF-8'))\n",
    "    except:\n",
    "        film_info.append('')\n",
    "\n",
    "    # extract country(ies)\n",
    "    try:\n",
    "        film_info.append(\" & \".join([country.text for country in film_soup.find('p', text=re.compile('Countr.*'), attrs={'class':'row-label'}).findNext('p').findAll('span')]).encode('UTF-8'))\n",
    "    except:\n",
    "        film_info.append('')\n",
    "\n",
    "    # extract year, genre, type, and category\n",
    "    for k in ['Year', 'Genre', 'Type', 'Category']:\n",
    "        try:\n",
    "            film_info.append(film_soup.find('p', text=k, attrs={'class':'row-label'}).findNext('p').find('span').contents[0].encode('UTF-8'))\n",
    "        except:\n",
    "            film_info.append('')\n",
    "\n",
    "    # append info on this single film to the list of all films\n",
    "    film_soup.decompose()\n",
    "    film_list.append(film_info)\n",
    "    print(film_info)\n",
    "\n",
    "# write film info to csv\n",
    "\n",
    "with open(os.getcwd()+'/bfi-films100.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(film_list)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
